import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime, timedelta, timezone
import os
import re
import json
import google.generativeai as genai
from urllib.parse import quote

# --- [1] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(layout="wide", page_title="Golden Key Pro | í€€íŠ¸ ëŒ€ì‹œë³´ë“œ")

THEME_DB_FILE = "theme_db.csv"

# ==========================================
# ğŸ›¡ï¸ [Security] Gemini API í‚¤ ë° ëª¨ë¸ ì—”ì§„ ì„¤ì •
# ==========================================
if "GEMINI_API_KEY" in st.secrets:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=GEMINI_API_KEY)
    try:
        model = genai.GenerativeModel(model_name='gemini-2.5-flash')
    except:
        model = None
else:
    GEMINI_API_KEY = "YOUR_GEMINI_API_KEY"
    model = None

# ==========================================
# ğŸ¨ [UI/UX] í”„ë¦¬ë¯¸ì—„ ëŒ€ì‹œë³´ë“œ ì»¤ìŠ¤í…€ CSS
# ==========================================
st.markdown(
    """
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Inter', sans-serif;
    }

    .stApp {
        background: #f1f5f9;
    }

    /* ğŸŒŸ ì§€ìˆ˜ í°íŠ¸ í¬ê¸° ìŠ¬ë¦¼í™” */
    [data-testid="stMetricValue"] {
        font-size: 1.25rem !important;
        font-weight: 800 !important;
    }
    [data-testid="stMetricLabel"] {
        font-size: 0.8rem !important;
        color: #64748b !important;
        margin-bottom: -5px !important;
    }

    /* ğŸŒŸ ì‹¤ì‹œê°„ ì£¼ë„ì£¼ ë¦¬ìŠ¤íŠ¸ ë””ìì¸ */
    .stock-card {
        background: white;
        border-radius: 8px;
        padding: 10px 14px;
        margin-bottom: 6px;
        display: flex;
        justify-content: space-between;
        align-items: center;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
        border-left: 5px solid #e2e8f0;
    }

    .left-zone { display: flex; align-items: center; gap: 8px; flex: 0 1 auto; }
    .center-zone { display: flex; align-items: center; gap: 8px; flex: 0 1 auto; margin-left: 10px; }
    .right-zone { display: flex; align-items: center; gap: 15px; flex: 1; justify-content: flex-end; }

    .stock-name { font-weight: 700; font-size: 1rem; color: #1e293b; white-space: nowrap; }
    
    .market-tag { 
        font-size: 0.65rem; 
        font-weight: 800; 
        padding: 2px 5px; 
        border-radius: 4px;
        white-space: nowrap;
    }
    .market-kospi { background-color: #dbeafe; color: #1e40af; }
    .market-kosdaq { background-color: #ffedd5; color: #9a3412; }

    .sector-badge {
        padding: 2px 10px;
        border-radius: 12px;
        font-size: 0.75rem;
        font-weight: 700;
        border: 1px solid #e2e8f0;
        white-space: nowrap;
    }

    /* ğŸŒŸ ìš°ì¸¡ ì„¹í„° ë¦¬ìŠ¤íŠ¸ ì¹¼ì •ë ¬ */
    .sector-item {
        font-size: 0.85rem;
        color: #334155;
        padding: 6px 0;
        display: flex;
        justify-content: space-between;
        align-items: center;
        border-bottom: 1px inset #f1f5f9;
        width: 100%;
    }

    .sector-item-left {
        display: flex;
        align-items: center;
        flex: 1;
        overflow: hidden;
    }
    .sector-stock-name {
        font-weight: 700;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }

    .sector-item-right {
        display: flex;
        align-items: center;
        justify-content: flex-end;
    }
    .val-rate {
        width: 65px;
        text-align: right;
        font-weight: 800;
        margin-right: 12px;
    }
    .val-vol {
        width: 75px;
        text-align: right;
        color: #64748b;
        font-size: 0.8rem;
    }

    .leader-label {
        font-size: 0.65rem;
        background: #ef4444;
        color: white;
        padding: 1px 4px;
        border-radius: 3px;
        margin-right: 5px;
        flex-shrink: 0;
    }

    /* ğŸŒŸ ì •ë°€ ë¶„ì„ íƒ­ ì „ìš© í”„ë¦¬ë¯¸ì—„ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .sector-group-title { font-size: 1.2rem; font-weight: 800; color: #1e293b; margin-top: 25px; margin-bottom: 10px; padding-bottom: 5px; border-bottom: 2px solid #cbd5e1; }
    .analysis-card {
        background: #ffffff; border-radius: 10px; padding: 16px; margin-bottom: 12px;
        border: 1px solid #e2e8f0; border-left: 5px solid #3b82f6; box-shadow: 0 4px 6px -1px rgba(0,0,0,0.05);
    }
    .ac-header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px; }
    .ac-title { font-size: 1.15rem; font-weight: 800; color: #0f172a; }
    .ac-vol { font-size: 0.9rem; font-weight: 700; color: #ef4444; background: #fee2e2; padding: 2px 8px; border-radius: 6px; }
    .ac-sectors { margin-bottom: 12px; display: flex; gap: 6px; flex-wrap: wrap; }
    .ac-sector-badge { background: #1e293b; color: #ffffff; padding: 3px 10px; border-radius: 12px; font-size: 0.75rem; font-weight: 700; }
    .ac-news { font-size: 1rem; color: #334155; line-height: 1.5; background: #f8fafc; padding: 10px; border-radius: 6px; }
    .ac-date { font-size: 0.8rem; color: #94a3b8; text-align: right; margin-top: 8px; font-weight: 600; }

    /* ì‚¬ì´ë“œë°” í…Œë§ˆ ì•„ì´í…œ ìŠ¤íƒ€ì¼ */
    .sidebar-theme-row {
        display: flex;
        justify-content: space-between;
        font-size: 0.85rem;
        padding: 8px 10px;
        margin-bottom: 5px;
        border-radius: 6px;
        font-weight: 700;
    }
    
    div[data-testid="column"]:nth-of-type(2) [data-testid="stVerticalBlock"] { gap: 0px !important; }
    div[data-testid="stExpander"] { border: 1px solid rgba(0,0,0,0.1) !important; margin-bottom: -1px !important; border-radius: 0px !important; }
    div[data-testid="stExpander"]:first-of-type { border-radius: 8px 8px 0 0 !important; }
    div[data-testid="stExpander"]:last-of-type { border-radius: 0 0 8px 8px !important; margin-bottom: 15px !important; }
    div[data-testid="stExpander"] summary { padding: 4px 12px !important; font-weight: 700 !important; }
    </style>
    """,
    unsafe_allow_html=True
)

# ==========================================
# ğŸŒŸ ì„¸ì…˜ ìƒíƒœ(Session State) ì´ˆê¸°í™”
# ==========================================
if 'global_indices' not in st.session_state: st.session_state.global_indices = []
if 'global_themes' not in st.session_state: st.session_state.global_themes = []
if 'global_briefing' not in st.session_state: st.session_state.global_briefing = "ê¸€ë¡œë²Œ ìŠ¤ìº”ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
if 'domestic_df' not in st.session_state: st.session_state.domestic_df = pd.DataFrame()
if 'analysis_results' not in st.session_state: st.session_state.analysis_results = []

# ==========================================
# ğŸŒŸ ì „ì—­ ì„¤ì • (ì„¹í„° ìƒ‰ìƒ ë™ê¸°í™”)
# ==========================================
SECTOR_COLORS = {
    'ë°˜ë„ì²´': '#dbeafe', 'ë¡œë´‡/AI': '#ede9fe', '2ì°¨ì „ì§€': '#d1fae5', 
    'ì „ë ¥/ì›ì „': '#fef3c7', 'ë°”ì´ì˜¤': '#fee2e2', 'ë°©ì‚°/ìš°ì£¼': '#f1f5f9', 
    'ê¸ˆìœµ/ì§€ì£¼': '#f3f4f6', 'ê°œë³„ì£¼': '#ffffff'
}

CUSTOM_SECTOR_MAP = {"ì˜¨ì½”ë‹‰í…Œë¼í“¨í‹±ìŠ¤": "ë°”ì´ì˜¤", "í˜„ëŒ€ADM": "ë°”ì´ì˜¤"}

# --- [2] ë¯¸ ì¦ì‹œ ì—”ì§„ (ì—ë””í„° ê°„ì„­ ë°©ì§€ URL ë¶„ë¦¬) ---

def get_kst_time():
    return datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')

def fetch_sox_stable():
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    url = "https://" + "finance.naver.com/world/"
    try:
        res = requests.get(url, headers=headers, timeout=10)
        res.encoding = 'euc-kr'
        soup = BeautifulSoup(res.text, 'html.parser')
        table = soup.find('table', {'class': 'tbl_exchange'})
        for row in table.find_all('tr'):
            tds = row.find_all('td')
            if len(tds) > 3 and "í•„ë¼ë¸í”¼ì•„ ë°˜ë„ì²´" in tds[0].text:
                return tds[1].text.strip(), tds[3].text.strip()
        return None, None
    except: return None, None

def fetch_robust_finance(ticker):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    try:
        url = "https://" + f"finance.yahoo.com/quote/{ticker}"
        res = requests.get(url, headers=headers, timeout=12)
        soup = BeautifulSoup(res.text, 'html.parser')
        val_tag = soup.find("fin-streamer", {"data-field": "regularMarketPrice"})
        rate_tag = soup.find("fin-streamer", {"data-field": "regularMarketChangePercent"})
        if val_tag and val_tag.text != "0.00" and val_tag.text != "":
            return val_tag.text, rate_tag.text.strip()
    except: pass
    try:
        google_ticker = ticker.replace('^', '.')
        mkt = "INDEXNASDAQ" if "NDX" in ticker or "SOX" in ticker else "INDEXSP"
        if "DJI" in ticker: mkt = "INDEXDJX"
        g_url = "https://" + f"www.google.com/finance/quote/{google_ticker}:{mkt}"
        g_res = requests.get(g_url, headers=headers, timeout=12)
        g_soup = BeautifulSoup(g_res.text, 'html.parser')
        g_val = g_soup.select_one(".YMlKec.fxKb9b").text
        g_rate = g_soup.select_one(".Jw796").text.replace('(', '').replace(')', '').strip()
        if g_val: return g_val, g_rate
    except: pass
    return "N/A", "0.00%"

def get_global_market_status():
    indices = []
    themes = []
    idx_map = {"ë‚˜ìŠ¤ë‹¥ 100": "^NDX", "S&P 500": "^GSPC", "ë‹¤ìš°ì¡´ìŠ¤": "^DJI"}
    
    try:
        for name, tk in idx_map.items():
            v, r = fetch_robust_finance(tk)
            indices.append({"name": name, "value": v, "delta": r})
            time.sleep(0.2)
        
        sox_v, sox_r = fetch_sox_stable()
        if not sox_v: sox_v, sox_r = fetch_robust_finance("^SOX")
        indices.append({"name": "í•„ë¼ ë°˜ë„ì²´", "value": sox_v, "delta": sox_r})

        etf_map = [("ë°˜ë„ì²´ (SOXX)", "SOXX", "ë°˜ë„ì²´"), ("ë¡œë´‡/AI (BOTZ)", "BOTZ", "ë¡œë´‡/AI"), ("2ì°¨ì „ì§€ (LIT)", "LIT", "2ì°¨ì „ì§€"), ("ì „ë ¥ë§ (GRID)", "GRID", "ì „ë ¥/ì›ì „"), ("ì›ìë ¥ (URA)", "URA", "ì „ë ¥/ì›ì „"), ("ë°”ì´ì˜¤ (IBB)", "IBB", "ë°”ì´ì˜¤")]
        for name, tk, sector in etf_map:
            _, r_etf = fetch_robust_finance(tk)
            themes.append({"name": name, "delta": r_etf, "color": SECTOR_COLORS.get(sector, "#ffffff")})
            time.sleep(0.2)
            
        st.session_state.global_indices = indices
        st.session_state.global_themes = themes
        st.session_state.global_briefing = f"ìµœì¢… ì—…ë°ì´íŠ¸: {get_kst_time()}\ní•´ì™¸ ì§€ìˆ˜ ë° ì „ë ¥/ì›ì „ í…Œë§ˆ ë³µêµ¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
    except: st.session_state.global_briefing = "í•´ì™¸ ì„œë²„ ë™ê¸°í™” ì¼ì‹œ ì§€ì—° ì¤‘"

def update_theme_db():
    session = requests.Session()
    session.headers.update({'User-Agent': 'Mozilla/5.0'})
    theme_dict = {}
    progress_bar = st.progress(0); status_text = st.empty()
    try:
        theme_links = []
        for i in range(1, 8):
            url = "https://" + f"finance.naver.com/sise/theme.naver?&page={i}"
            res = session.get(url, timeout=5); res.encoding = 'euc-kr'
            soup = BeautifulSoup(res.text, 'html.parser')
            links = soup.select('.type_1.theme td.col_type1 a')
            for link in links: theme_links.append((link.text.strip(), "https://finance.naver.com" + link['href']))
        
        total_themes = len(theme_links)
        for idx, (theme_name, link) in enumerate(theme_links):
            status_text.text(f"ğŸš€ í…Œë§ˆ DB ê°±ì‹  ì¤‘... ({idx+1}/{total_themes})")
            progress_bar.progress((idx + 1) / total_themes)
            detail_res = session.get(link, timeout=5); detail_res.encoding = 'euc-kr'
            detail_soup = BeautifulSoup(detail_res.text, 'html.parser')
            stocks = detail_soup.select('.type_5 td.name a')
            for stock in stocks:
                name = stock.text.strip()
                if name in theme_dict:
                    if theme_name not in theme_dict[name]: theme_dict[name] += f", {theme_name}"
                else: theme_dict[name] = theme_name
            time.sleep(0.02)
            
        pd.DataFrame(list(theme_dict.items()), columns=['ì¢…ëª©ëª…', 'í…Œë§ˆ']).to_csv(THEME_DB_FILE, index=False, encoding='utf-8-sig')
        status_text.success("âœ… í…Œë§ˆ DB ì—…ë°ì´íŠ¸ ì™„ë£Œ!"); time.sleep(1); st.rerun()
    except Exception as e: status_text.error(f"ì˜¤ë¥˜: {e}")

# --- [4] ğŸ’¡ ì¢…ëª© ì •ë°€ ë¶„ì„ ì—”ì§„ ---

def fetch_stock_news_headlines(stock_name):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8',
        'Referer': "https://" + "finance.naver.com/"
    }
    titles = []
    try:
        encoded_kw = quote(f"íŠ¹ì§•ì£¼ {stock_name}", encoding='euc-kr')
        fin_url = "https://" + f"finance.naver.com/news/news_search.naver?q={encoded_kw}"
        res_fin = requests.get(fin_url, headers=headers, timeout=10)
        res_fin.encoding = 'euc-kr' 
        
        if res_fin.status_code == 200:
            soup_fin = BeautifulSoup(res_fin.text, 'html.parser')
            tags = soup_fin.select(".articleSubject a") or soup_fin.select(".tit") or soup_fin.select("dt a")
            for tag in tags[:10]:
                text = tag.text.strip()
                if text: titles.append(text)
    except: pass 

    if not titles:
        try:
            gen_url = "https://" + "search.naver.com/search.naver"
            params = {'where': 'news', 'query': f'íŠ¹ì§•ì£¼ {stock_name}', 'sort': '0'} 
            headers['Referer'] = "https://" + "search.naver.com/"
            
            res_gen = requests.get(gen_url, params=params, headers=headers, timeout=10)
            if res_gen.status_code == 200:
                soup_gen = BeautifulSoup(res_gen.text, 'html.parser')
                selectors = [".news_tit", ".title_link", "a.news_tit", ".dsc_txt_tit", ".api_txt_lines"]
                for sel in selectors:
                    tags = soup_gen.select(sel)
                    if tags: 
                        for tag in tags[:10]:
                            text = tag.text.strip()
                            if text: titles.append(text)
                        break 
        except: pass
            
    if not titles:
        return [f"[ì—ëŸ¬] ë„¤ì´ë²„ ê²€ìƒ‰ ì „ë©´ ì°¨ë‹¨ë¨ (1, 2ì°¨ ì‚¬ëƒ¥í„° ëª¨ë‘ ì‹¤íŒ¨)"]
        
    unique_titles = []
    for t in titles:
        if t not in unique_titles: unique_titles.append(t)
            
    return unique_titles[:10]

def perform_batch_analysis(news_map):
    if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY":
        return [{"ì¢…ëª©ëª…": "ì˜¤ë¥˜", "ì„¹í„°": ["ì‹œìŠ¤í…œ"], "ì´ìœ ": "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "ê¸°ì‚¬ë‚ ì§œ": "-"}]
    
    try:
        analysis_model = genai.GenerativeModel('gemini-2.5-flash')
        
        prompt = f"""
        ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ í€€íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
        ì•„ë˜ ë°ì´í„°ëŠ” ì‹¤ì‹œê°„ ì£¼ë„ì£¼ë“¤ì— ëŒ€í•´ ë„¤ì´ë²„ ë‰´ìŠ¤ ì œëª©ì„ ì¢…ëª©ë‹¹ ìµœëŒ€ 10ê°œì”© í¬ë¡¤ë§í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
        
        [ë°ì´í„°]
        {json.dumps(news_map, ensure_ascii=False)}
        
        [ì¶œë ¥ ì–‘ì‹ ë° ë¶„ì„ ê·œì¹™]
        1. ê° ì¢…ëª©ë‹¹ ì œê³µëœ ì—¬ëŸ¬ ê°œì˜ ë‰´ìŠ¤ ì œëª©ì„ ëª¨ë‘ ì½ê³ , í•´ë‹¹ ì¢…ëª©ì´ ìƒìŠ¹í•œ 'ì§„ì§œ í•µì‹¬ ì¬ë£Œ'ë¥¼ íŒŒì•…í•˜ì„¸ìš”.
        2. íƒ€ ì¢…ëª© ê¸°ì‚¬ëŠ” ë¬´ì‹œí•˜ê³ , ë°ì´í„°ì— "[ì—ëŸ¬]" ë¼ê³  ì í˜€ìˆë‹¤ë©´ ì´ìœ ë¥¼ "[ì—ëŸ¬] í¬ë¡¤ë§ ì‹¤íŒ¨" ë¼ê³  ì ì–´ì£¼ì„¸ìš”.
        3. 'ì„¹í„°'ëŠ” í•´ë‹¹ ì¬ë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨í•˜ë˜, ê¼­ 1ê°œê°€ ì•„ë‹ˆì–´ë„ ë©ë‹ˆë‹¤. ì—°ê´€ëœ ëª¨ë“  ì„¹í„°ë¥¼ ë°°ì—´ í˜•íƒœë¡œ ì¶”ì¶œí•˜ì„¸ìš”. (ì˜ˆ: ["ë°˜ë„ì²´", "ë¡œë´‡/AI"]).
        4. ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ ìˆœìˆ˜ JSON ë°°ì—´(Array) í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë°±í‹±(`)ì´ë‚˜ ë¶€ê°€ ì„¤ëª…ì€ ì ˆëŒ€ ë„£ì§€ ë§ˆì„¸ìš”.
        
        [ì˜ˆì‹œ]
        [
          {{"ì¢…ëª©ëª…": "ì‚¼ì„±ì „ì", "ì„¹í„°": ["ë°˜ë„ì²´", "ë¡œë´‡/AI"], "ì´ìœ ": "ì—”ë¹„ë””ì•„ HBM í€„í…ŒìŠ¤íŠ¸ í†µê³¼ ê¸°ëŒ€ê°", "ê¸°ì‚¬ë‚ ì§œ": "ìµœê·¼ íŠ¹ì§•ì£¼"}},
          {{"ì¢…ëª©ëª…": "ì¹´ì¹´ì˜¤", "ì„¹í„°": ["ê¸ˆìœµ/ì§€ì£¼"], "ì´ìœ ": "ìµœê·¼ ì£¼ìš” ì¬ë£Œ ë°œê²¬ ì•ˆ ë¨", "ê¸°ì‚¬ë‚ ì§œ": "-"}}
        ]
        """
        response = analysis_model.generate_content(prompt)
        
        raw_text = response.text.strip()
        raw_text = re.sub(r"^```json\n?|^```\n?", "", raw_text) 
        raw_text = re.sub(r"\n?```$", "", raw_text)
        
        return json.loads(raw_text)
    except Exception as e:
        return [{"ì¢…ëª©ëª…": "ë¶„ì„ ì‹œìŠ¤í…œ ì—ëŸ¬", "ì„¹í„°": ["ì—ëŸ¬"], "ì´ìœ ": f"Gemini ë¶„ì„ ì˜¤ë¥˜: {str(e)}", "ê¸°ì‚¬ë‚ ì§œ": "-"}]

# --- [5] êµ­ë‚´ ë°ì´í„° í¬ë¡¤ë§ ë° ë¶„ë¥˜ ë¡œì§ ---

def fetch_market_data(sosok, market_name):
    # ğŸ’¡ [í•µì‹¬ ë°©ì–´ë§‰]: ì—ë””í„°ê°€ ì ˆëŒ€ URLë¡œ ì¸ì‹í•˜ì§€ ëª»í•˜ê²Œ ë¬¸ìì—´ì„ ë¶„ë¦¬í•´ì„œ ì¡°ë¦½í•©ë‹ˆë‹¤!
    protocol = "https"
    host = "finance.naver.com"
    path = "sise/sise_quant.naver"
    
    url = f"{protocol}://{host}/{path}?sosok={sosok}"
    referer_url = f"{protocol}://{host}/"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
        'Referer': referer_url
    }
    try:
        res = requests.get(url, headers=headers, timeout=5)
        res.encoding = 'euc-kr'
        soup = BeautifulSoup(res.text, 'html.parser')
        table = soup.find('table', {'class': 'type_2'})
        
        if not table:
            st.error(f"[ì—ëŸ¬] ë„¤ì´ë²„ ê¸ˆìœµ ì ‘ê·¼ ì°¨ë‹¨ë¨ ({market_name})")
            return pd.DataFrame()
            
        data = []
        for tr in table.find_all('tr'):
            tds = tr.find_all('td')
            if len(tds) > 5:
                data.append({'ì‹œì¥': market_name, 'ì¢…ëª©ëª…': tds[1].text.strip(), 'ë“±ë½ë¥ ': tds[4].text.strip(), 'ê±°ë˜ëŒ€ê¸ˆ': tds[6].text.strip()})
        return pd.DataFrame(data)
    except Exception as e: 
        st.error(f"[ì—ëŸ¬] {market_name} ë°ì´í„° ìˆ˜ì§‘ ì¤‘ í†µì‹  ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

def apply_mega_sector(row):
    stock_name = row['ì¢…ëª©ëª…']; t = str(row['í…Œë§ˆ'])
    if stock_name in CUSTOM_SECTOR_MAP: return CUSTOM_SECTOR_MAP[stock_name]
    keywords = {'ë°˜ë„ì²´': ['ë°˜ë„ì²´', 'HBM', 'CXL', 'ì˜¨ë””ë°”ì´ìŠ¤', 'ë©”ëª¨ë¦¬', 'NPU', 'ìœ ë¦¬ê¸°íŒ'], '2ì°¨ì „ì§€': ['2ì°¨ì „ì§€', 'ë¦¬íŠ¬', 'ì „ê³ ì²´', 'ë°°í„°ë¦¬'], 'ë°”ì´ì˜¤': ['ë°”ì´ì˜¤', 'ì œì•½', 'ì‹ ì•½', 'ì„ìƒ', 'ë¹„ë§Œ'], 'ë¡œë´‡/AI': ['ë¡œë´‡', 'AI', 'ì¸ê³µì§€ëŠ¥'], 'ì „ë ¥/ì›ì „': ['ì „ë ¥', 'ì „ì„ ', 'ì›ìë ¥'], 'ë°©ì‚°/ìš°ì£¼': ['ë°©ì‚°', 'ìš°ì£¼', 'í•­ê³µ'], 'ê¸ˆìœµ/ì§€ì£¼': ['ì§€ì£¼ì‚¬', 'ì€í–‰', 'ì¦ê¶Œ', 'ë°¸ë¥˜ì—…']}
    for sector, keys in keywords.items():
        if any(k in t for k in keys): return sector
    return 'ê°œë³„ì£¼'

def format_volume_to_jo_eok(x_million):
    try:
        clean_val = str(x_million).replace(',', '')
        val_num = float(clean_val)
        eok = int(val_num / 100)
        return f"{eok // 10000}ì¡° {eok % 10000}ì–µ" if eok >= 10000 else f"{eok}ì–µ"
    except: return str(x_million)

# --- [6] UI ë ˆì´ì•„ì›ƒ êµ¬ì„± ---

with st.sidebar:
    st.title("ğŸŒ ê¸€ë¡œë²Œ ì¦ì‹œ")
    if st.button("ğŸš€ ê¸€ë¡œë²Œ ì‹¤ì‹œê°„ ìŠ¤ìº”", use_container_width=True):
        get_global_market_status()
    if st.session_state.global_indices:
        for idx in st.session_state.global_indices:
            st.metric(label=idx['name'], value=idx['value'], delta=idx['delta'], delta_color="normal" if '+' in str(idx['delta']) else "inverse")
    st.markdown("---")
    st.subheader("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ í…Œë§ˆ(ETF) íë¦„")
    if st.session_state.global_themes:
        for t in st.session_state.global_themes:
            v_c = "#ef4444" if '+' in str(t['delta']) else "#2563eb"
            st.markdown(f'<div class="sidebar-theme-row" style="background-color: {t["color"]};"><span style="color: #1e293b;">{t["name"]}</span><span style="color: {v_c};">{t["delta"]}</span></div>', unsafe_allow_html=True)
    st.info(f"ğŸ“ **ì „ë¬¸ê°€ ë¸Œë¦¬í•‘:**\n{st.session_state.global_briefing}")

col_title, col_btn = st.columns([7, 3])
with col_title: st.title("ğŸ”‘ Golden Key Pro")
with col_btn:
    st.write(""); st.write("")
    if st.button("ğŸ”„ í…Œë§ˆ DB ìµœì‹ í™”", use_container_width=True): update_theme_db()

tab_scanner, tab_analysis = st.tabs(["ğŸš€ ì‹¤ì‹œê°„ ì£¼ë„ì£¼ ìŠ¤ìºë„ˆ", "ğŸ“Š ì¢…ëª© ì •ë°€ ë¶„ì„"])

with tab_scanner:
    col_main, col_summary = st.columns([7, 3])
    with col_summary:
        st.subheader("ğŸ† ì£¼ë„ ì„¹í„°")
        summary_placeholder = st.empty()
    with col_main:
        if st.button("ğŸš€ êµ­ë‚´ ì‹¤ì‹œê°„ ìŠ¤ìº” ì‹¤í–‰", use_container_width=True):
            with st.spinner("êµ­ë‚´ ì‹œì¥ ìˆ˜ê¸‰ ë¶„ì„ ì¤‘..."):
                df_k = fetch_market_data(0, 'ì½”ìŠ¤í”¼')
                df_q = fetch_market_data(1, 'ì½”ìŠ¤ë‹¥')
                df = pd.concat([df_k, df_q], ignore_index=True)
                
                if df.empty:
                    st.warning("âš ï¸ ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì ‘ì† ì°¨ë‹¨ ë˜ëŠ” ì„œë²„ ì‘ë‹µ ì—†ìŒ)")
                else:
                    df = df[~df['ì¢…ëª©ëª…'].str.contains('KODEX|TIGER|ACE|SOL|KBSTAR|HANARO|KOSEF|ARIRANG|ìŠ¤íŒ©|ETN|ì„ ë¬¼|ì¸ë²„ìŠ¤|ë ˆë²„ë¦¬ì§€|VIX|ì˜µì…˜|ë§ˆì´í‹°|íˆì–´ë¡œì¦ˆ|TIMEFOLIO', na=False)]
                    
                    df['ë“±ë½ë¥ _num'] = pd.to_numeric(df['ë“±ë½ë¥ '].str.replace(r'%|\+', '', regex=True), errors='coerce')
                    df['ê±°ë˜ëŒ€ê¸ˆ_num'] = pd.to_numeric(df['ê±°ë˜ëŒ€ê¸ˆ'].str.replace(',', ''), errors='coerce')
                    df = df.sort_values(by='ê±°ë˜ëŒ€ê¸ˆ_num', ascending=False).head(40)
                    df = df[df['ë“±ë½ë¥ _num'] >= 4.0]
                    
                    if df.empty:
                        st.info("â„¹ï¸ í˜„ì¬ 4% ì´ìƒ ìƒìŠ¹í•œ ì£¼ë„ì£¼(ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„)ê°€ ì—†ìŠµë‹ˆë‹¤. (ì¥ì´ ì—´ë¦¬ì§€ ì•Šì€ ì´ë¥¸ ì•„ì¹¨ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")
                    else:
                        if os.path.exists(THEME_DB_FILE):
                            t_df = pd.read_csv(THEME_DB_FILE)
                            df['í…Œë§ˆ'] = df['ì¢…ëª©ëª…'].map(dict(zip(t_df['ì¢…ëª©ëª…'], t_df['í…Œë§ˆ']))).fillna('-')
                        else: df['í…Œë§ˆ'] = '-'
                        df['ì„¹í„°'] = df.apply(apply_mega_sector, axis=1)
                        st.session_state.domestic_df = df
        
        if not st.session_state.domestic_df.empty:
            for _, row in st.session_state.domestic_df.iterrows():
                bg = SECTOR_COLORS.get(row['ì„¹í„°'], '#ffffff')
                rv = row['ë“±ë½ë¥ _num']; rt_c = "#ef4444" if rv >= 20.0 else ("#22c55e" if rv >= 10.0 else "#1f2937")
                st.markdown(f'<div class="stock-card"><div class="left-zone"><span class="market-tag {"market-kospi" if row["ì‹œì¥"]=="ì½”ìŠ¤í”¼" else "market-kosdaq"}">{row["ì‹œì¥"]}</span><span class="stock-name">{row["ì¢…ëª©ëª…"]}</span></div><div class="center-zone"><span class="sector-badge" style="background: {bg}; color: #1e293b;">{row["ì„¹í„°"]}</span></div><div class="right-zone"><span style="color: {rt_c}; font-weight: 800; font-size: 1.1rem; min-width: 65px; text-align: right;">+{rv}%</span><span class="stock-vol">{format_volume_to_jo_eok(row["ê±°ë˜ëŒ€ê¸ˆ_num"])}</span></div></div>', unsafe_allow_html=True)
            with summary_placeholder.container():
                s_group = st.session_state.domestic_df[st.session_state.domestic_df['ì„¹í„°'] != 'ê°œë³„ì£¼'].groupby('ì„¹í„°').size().sort_values(ascending=False)
                for s_name, count in s_group.items():
                    with st.expander(f"**{s_name}** ({count})", expanded=True):
                        s_stocks = st.session_state.domestic_df[st.session_state.domestic_df['ì„¹í„°'] == s_name].sort_values('ë“±ë½ë¥ _num', ascending=False)
                        for idx_l, (idx, s_row) in enumerate(s_stocks.iterrows()):
                            ldr = '<span class="leader-label">ëŒ€ì¥</span>' if idx_l == 0 else ''
                            st.markdown(f'<div class="sector-item"><div class="sector-item-left">{ldr}<span class="sector-stock-name">{s_row["ì¢…ëª©ëª…"]}</span></div><div class="sector-item-right"><span class="val-rate" style="color:{"#ef4444" if s_row["ë“±ë½ë¥ _num"]>=20 else "#334155"};">+{s_row["ë“±ë½ë¥ _num"]}%</span><span class="val-vol">{format_volume_to_jo_eok(s_row["ê±°ë˜ëŒ€ê¸ˆ_num"])}</span></div></div>', unsafe_allow_html=True)

with tab_analysis:
    st.subheader("ğŸ” ë‰´ìŠ¤ ê¸°ë°˜ í…Œë§ˆ ì •ë°€ ë¶„ì„ (Gemini LLM)")
    if st.session_state.domestic_df.empty:
        st.info("ì‹¤ì‹œê°„ ì£¼ë„ì£¼ ìŠ¤ìº”ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        if st.button("ğŸ” ë‰´ìŠ¤ í¬ë¡¤ë§ ë° Gemini ì •ë°€ ë¶„ì„ ì‹œì‘", use_container_width=True):
            with st.spinner("ì•ˆì „í•œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì •ë°€ ë¶„ì„ì„ ìœ„í•´ ì•½ 1~2ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤. ì ì‹œë§Œ ëŒ€ê¸°í•´ ì£¼ì„¸ìš”..."):
                news_payload = {}
                progress_bar = st.progress(0)
                stocks = st.session_state.domestic_df['ì¢…ëª©ëª…'].tolist()
                for i, name in enumerate(stocks):
                    news_payload[name] = fetch_stock_news_headlines(name)
                    progress_bar.progress((i + 1) / len(stocks))
                    time.sleep(2.0) 
                
                with st.expander("ğŸš¨ [ë””ë²„ê¹…] í¬ë¡¤ëŸ¬ê°€ ìˆ˜ì§‘í•œ ë“€ì–¼ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸", expanded=False):
                    st.json(news_payload)
                
                st.session_state.analysis_results = perform_batch_analysis(news_payload)
                st.success("âœ… ì •ë°€ ë¶„ì„ ì™„ë£Œ!")

        if st.session_state.analysis_results:
            grouped_data = {}
            
            for item in st.session_state.analysis_results:
                if isinstance(item, str):
                    continue
                    
                stock_name = item.get("ì¢…ëª©ëª…", "ì•Œ ìˆ˜ ì—†ìŒ")
                
                vol_str = "N/A"
                if not st.session_state.domestic_df.empty:
                    match_row = st.session_state.domestic_df[st.session_state.domestic_df['ì¢…ëª©ëª…'] == stock_name]
                    if not match_row.empty:
                        vol_str = format_volume_to_jo_eok(match_row.iloc[0]['ê±°ë˜ëŒ€ê¸ˆ_num'])
                
                item['ê±°ë˜ëŒ€ê¸ˆ'] = vol_str
                
                sectors = item.get("ì„¹í„°", ["ê°œë³„ì£¼"])
                main_sector = sectors[0] if isinstance(sectors, list) and len(sectors) > 0 else "ê°œë³„ì£¼"
                
                if main_sector not in grouped_data:
                    grouped_data[main_sector] = []
                grouped_data[main_sector].append(item)
            
            st.markdown('<div class="analysis-list-container">', unsafe_allow_html=True)
            for sector, items in grouped_data.items():
                st.markdown(f'<div class="sector-group-title">ğŸ¯ {sector} ê´€ë ¨ì£¼</div>', unsafe_allow_html=True)
                
                for item in items:
                    sectors_list = item.get("ì„¹í„°", [])
                    if isinstance(sectors_list, str): sectors_list = [sectors_list]
                    
                    badge_html = "".join([f'<span class="ac-sector-badge">{s}</span>' for s in sectors_list])
                    
                    card_html = f"""
                    <div class="analysis-card">
                        <div class="ac-header">
                            <span class="ac-title">{item.get('ì¢…ëª©ëª…', '')}</span>
                            <span class="ac-vol">ğŸ’° ê±°ë˜ëŒ€ê¸ˆ: {item.get('ê±°ë˜ëŒ€ê¸ˆ', '')}</span>
                        </div>
                        <div class="ac-sectors">
                            {badge_html}
                        </div>
                        <div class="ac-news">
                            ğŸ“° <b>ìƒìŠ¹ ì´ìœ :</b> {item.get('ì´ìœ ', '')}
                        </div>
                        <div class="ac-date">ğŸ•’ ê¸°ì‚¬ë‚ ì§œ: {item.get('ê¸°ì‚¬ë‚ ì§œ', '')}</div>
                    </div>
                    """
                    st.markdown(card_html, unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)